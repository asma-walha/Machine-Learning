{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOZSl/c79RCLzYQLihHfgks",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asma-walha/Machine-Learning/blob/main/eeg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Up the Environment"
      ],
      "metadata": {
        "id": "9y_pJNeweJ4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XD0Zm0Vyv3Td",
        "outputId": "820b61f5-e8d4-4ed1-c60d-4e6d6c03021c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Feb 17 15:29:24 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!free -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0hU4XfLv91n",
        "outputId": "af9b766c-148a-45ee-d5a9-9300fa0c55d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            12Gi       1.6Gi       9.1Gi       2.0Mi       1.9Gi        10Gi\n",
            "Swap:             0B          0B          0B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P_81coXre3p",
        "outputId": "0d066cfb-7c65-46e7-a993-b7b1275c07ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.5)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.1.31)\n",
            "Downloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "X97QU3K6d9MZ"
      },
      "outputs": [],
      "source": [
        "import mne\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess EEG Data\n"
      ],
      "metadata": {
        "id": "5N36E40veNa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a sample EEG dataset (e.g., the MNE sample dataset)\n",
        "sample_data_folder = mne.datasets.sample.data_path()\n",
        "sample_data_raw_file = sample_data_folder / 'MEG' / 'sample' / 'sample_audvis_raw.fif'\n",
        "raw = mne.io.read_raw_fif(sample_data_raw_file, preload=True)\n",
        "\n",
        "# Print information about the dataset\n",
        "print(raw.info)\n",
        "\n",
        "# Après le chargement des données\n",
        "print(f\"Shape of raw data: {raw.get_data().shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2sx06Jsrnzw",
        "outputId": "d7b2e544-6c31-4441-b690-f396c4d026fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using default location ~/mne_data for sample...\n",
            "Creating /root/mne_data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading file 'MNE-sample-data-processed.tar.gz' from 'https://osf.io/86qa2/download?version=6' to '/root/mne_data'.\n",
            "100%|█████████████████████████████████████| 1.65G/1.65G [00:00<00:00, 1.69TB/s]\n",
            "Untarring contents of '/root/mne_data/MNE-sample-data-processed.tar.gz' to '/root/mne_data'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to create new mne-python configuration file:\n",
            "/root/.mne/mne-python.json\n",
            "Download complete in 04m37s (1576.2 MB)\n",
            "Opening raw data file /root/mne_data/MNE-sample-data/MEG/sample/sample_audvis_raw.fif...\n",
            "    Read a total of 3 projection items:\n",
            "        PCA-v1 (1 x 102)  idle\n",
            "        PCA-v2 (1 x 102)  idle\n",
            "        PCA-v3 (1 x 102)  idle\n",
            "    Range : 25800 ... 192599 =     42.956 ...   320.670 secs\n",
            "Ready.\n",
            "Reading 0 ... 166799  =      0.000 ...   277.714 secs...\n",
            "<Info | 21 non-empty values\n",
            " acq_pars: ACQch001 110113 ACQch002 110112 ACQch003 110111 ACQch004 110122 ...\n",
            " bads: 2 items (MEG 2443, EEG 053)\n",
            " ch_names: MEG 0113, MEG 0112, MEG 0111, MEG 0122, MEG 0123, MEG 0121, MEG ...\n",
            " chs: 204 Gradiometers, 102 Magnetometers, 9 Stimulus, 60 EEG, 1 EOG\n",
            " custom_ref_applied: False\n",
            " description: acquisition (megacq) VectorView system at NMR-MGH\n",
            " dev_head_t: MEG device -> head transform\n",
            " dig: 146 items (3 Cardinal, 4 HPI, 61 EEG, 78 Extra)\n",
            " events: 1 item (list)\n",
            " experimenter: MEG\n",
            " file_id: 4 items (dict)\n",
            " highpass: 0.1 Hz\n",
            " hpi_meas: 1 item (list)\n",
            " hpi_results: 1 item (list)\n",
            " lowpass: 172.2 Hz\n",
            " meas_date: 2002-12-03 19:01:10 UTC\n",
            " meas_id: 4 items (dict)\n",
            " nchan: 376\n",
            " proj_id: 1 item (ndarray)\n",
            " proj_name: test\n",
            " projs: PCA-v1: off, PCA-v2: off, PCA-v3: off\n",
            " sfreq: 600.6 Hz\n",
            ">\n",
            "Shape of raw data: (376, 166800)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the EEG data\n",
        "def preprocess_eeg(raw, l_freq=0.1, h_freq=38, resample_rate=256):\n",
        "    # Filter the data\n",
        "    raw.filter(l_freq=l_freq, h_freq=h_freq)\n",
        "\n",
        "    raw.pick_types(eeg=True)  # Ne garde que les canaux EEG\n",
        "\n",
        "    # Resample the data\n",
        "    raw.resample(resample_rate)\n",
        "\n",
        "    # Re-reference to average\n",
        "    raw.set_eeg_reference(ref_channels='average')\n",
        "\n",
        "    # Segment into epochs (e.g., 4 seconds)\n",
        "    epochs = mne.make_fixed_length_epochs(raw, duration=4.0)\n",
        "    return epochs.get_data()\n",
        "\n",
        "epochs_data = preprocess_eeg(raw)\n",
        "print(f\"Shape of epochs data: {epochs_data.shape}\")\n",
        "epochs_tensor = torch.tensor(epochs_data, dtype=torch.float32)\n",
        "print(f\"Shape of epochs tensor: {epochs_tensor.shape}\")\n",
        "\n",
        "# Create a dataset and DataLoader\n",
        "dataset = TensorDataset(epochs_tensor)\n",
        "batch_size = 32\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v68fzMMxeDn6",
        "outputId": "89d2a1c3-fced-49af-a42a-1a37dbd2073d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.1 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.10\n",
            "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 19821 samples (33.001 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.8s\n",
            "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:    3.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
            "EEG channel type selected for re-referencing\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "Not setting metadata\n",
            "69 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 69 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n",
            "Shape of epochs data: (69, 59, 1024)\n",
            "Shape of epochs tensor: torch.Size([69, 59, 1024])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the EEGPT Architecture"
      ],
      "metadata": {
        "id": "ZdVnb6UoeRPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EEGPT(nn.Module):\n",
        "    def __init__(self, num_channels, num_timepoints, embed_dim, num_layers):\n",
        "        super(EEGPT, self).__init__()\n",
        "        self.num_channels = num_channels\n",
        "        self.num_timepoints = num_timepoints\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        # Local spatio-temporal embedding\n",
        "        self.embedding = nn.Linear(num_timepoints, embed_dim)\n",
        "\n",
        "        # Transformer encoder with batch_first=True\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=8, batch_first=True)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Momentum encoder\n",
        "        self.momentum_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Predictor and reconstructor\n",
        "        self.predictor = nn.Linear(embed_dim, embed_dim)\n",
        "        self.reconstructor = nn.Linear(embed_dim, num_timepoints)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        batch_size, num_channels, num_timepoints = x.shape\n",
        "\n",
        "        # Apply masking to the input tensor\n",
        "        masked_x = x * mask  # Shape: (batch_size, num_channels, num_timepoints)\n",
        "\n",
        "        # Reshape for embedding: (batch_size * num_channels, num_timepoints)\n",
        "        masked_x = masked_x.view(-1, num_timepoints)\n",
        "\n",
        "        # Apply local spatio-temporal embedding\n",
        "        embedded_x = self.embedding(masked_x)  # Shape: (batch_size * num_channels, embed_dim)\n",
        "\n",
        "        # Reshape back: (batch_size, num_channels, embed_dim)\n",
        "        embedded_x = embedded_x.view(batch_size, num_channels, self.embed_dim)\n",
        "\n",
        "        # Encode the masked input\n",
        "        enc_output = self.encoder(embedded_x)  # Shape: (batch_size, num_channels, embed_dim)\n",
        "\n",
        "        # Predict the full features\n",
        "        pred_output = self.predictor(enc_output)  # Shape: (batch_size, num_channels, embed_dim)\n",
        "\n",
        "        # Reshape for reconstruction: (batch_size * num_channels, embed_dim)\n",
        "        pred_output_reshaped = pred_output.view(-1, self.embed_dim)\n",
        "\n",
        "        # Reconstruct the masked parts\n",
        "        recon_output = self.reconstructor(pred_output_reshaped)  # Shape: (batch_size * num_channels, num_timepoints)\n",
        "\n",
        "        # Reshape back: (batch_size, num_channels, num_timepoints)\n",
        "        recon_output = recon_output.view(batch_size, num_channels, self.num_timepoints)\n",
        "\n",
        "        # Apply embedding to the input for the momentum encoder\n",
        "        full_x = x.view(-1, num_timepoints)  # Shape: (batch_size * num_channels, num_timepoints)\n",
        "        embedded_full_x = self.embedding(full_x)  # Shape: (batch_size * num_channels, embed_dim)\n",
        "        embedded_full_x = embedded_full_x.view(batch_size, num_channels, self.embed_dim)  # Reshape back\n",
        "        momentum_output = self.momentum_encoder(embedded_full_x)  # Shape: (batch_size, num_channels, embed_dim)\n",
        "\n",
        "        return enc_output, pred_output, recon_output, momentum_output"
      ],
      "metadata": {
        "id": "XyN1cPpSeGQS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test avec des données factices\n",
        "batch_size = 32\n",
        "num_channels = 59\n",
        "num_timepoints = 1024\n",
        "embed_dim = 512\n",
        "\n",
        "x = torch.randn(batch_size, num_channels, num_timepoints)\n",
        "mask = torch.rand(batch_size, num_channels, num_timepoints) > 0.5\n",
        "print(f\"Shape of x: {x.shape}\")\n",
        "print(f\"Shape of mask: {mask.shape}\")\n",
        "\n",
        "model = EEGPT(num_channels, num_timepoints, embed_dim, num_layers=8)\n",
        "enc_output, pred_output, recon_output, momentum_output = model(x, mask)\n",
        "\n",
        "print(f\"Shape of enc_output: {enc_output.shape}\")  # Doit être (batch_size, num_channels, embed_dim)\n",
        "print(f\"Shape of pred_output: {pred_output.shape}\")  # Doit être (batch_size, num_channels, embed_dim)\n",
        "print(f\"Shape of recon_output: {recon_output.shape}\")  # Doit être (batch_size, num_channels, num_timepoints)\n",
        "print(f\"Shape of momentum_output: {momentum_output.shape}\")  # Doit être (batch_size, num_channels, embed_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2bI1Awr1PWu",
        "outputId": "c3772b1e-5dca-4e0b-9a0f-d84251b2e2b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x: torch.Size([32, 59, 1024])\n",
            "Shape of mask: torch.Size([32, 59, 1024])\n",
            "Shape of enc_output: torch.Size([32, 59, 512])\n",
            "Shape of pred_output: torch.Size([32, 59, 512])\n",
            "Shape of recon_output: torch.Size([32, 59, 1024])\n",
            "Shape of momentum_output: torch.Size([32, 59, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the Dual Self-Supervised Loss"
      ],
      "metadata": {
        "id": "l1MXUV4WeWd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def dual_self_supervised_loss(enc_output, pred_output, recon_output, momentum_output, mask):\n",
        "    # Alignment loss\n",
        "    alignment_loss = nn.MSELoss()(pred_output, momentum_output)\n",
        "\n",
        "    # Resize recon_output to match enc_output's dimensions\n",
        "    recon_output_resized = F.interpolate(recon_output.permute(0, 2, 1), size=512, mode='linear', align_corners=False).permute(0, 2, 1)\n",
        "\n",
        "    # Resize mask to match recon_output_resized's dimensions\n",
        "    mask_resized = F.interpolate(mask.permute(0, 2, 1), size=512, mode='nearest').permute(0, 2, 1)\n",
        "\n",
        "    # Reconstruction loss\n",
        "    reconstruction_loss = nn.MSELoss()(recon_output_resized * mask_resized, enc_output * mask_resized)\n",
        "\n",
        "    # Total loss\n",
        "    total_loss = alignment_loss + reconstruction_loss\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "2nwnHISQeZrc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random masks\n",
        "def generate_mask(x, mask_time_ratio=0.5, mask_channel_ratio=0.8):\n",
        "    batch_size, num_channels, num_timepoints = x.shape\n",
        "    time_mask = torch.rand(batch_size, num_timepoints) > mask_time_ratio  # Shape: (batch_size, num_timepoints)\n",
        "    channel_mask = torch.rand(batch_size, num_channels) > mask_channel_ratio  # Shape: (batch_size, num_channels)\n",
        "    mask = time_mask.unsqueeze(1) * channel_mask.unsqueeze(2)  # Shape: (batch_size, num_channels, num_timepoints)\n",
        "    return mask.float()"
      ],
      "metadata": {
        "id": "J-Qjp6f8s5q7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Model\n"
      ],
      "metadata": {
        "id": "CLWZZd3AebsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, optimizer, and scheduler\n",
        "model = EEGPT(num_channels=376, num_timepoints=1024, embed_dim=512, num_layers=8)\n",
        "optimizer = AdamW(model.parameters(), lr=2.5e-4)\n",
        "scheduler = OneCycleLR(optimizer, max_lr=5e-4, total_steps=200)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(200):\n",
        "    for batch in dataloader:\n",
        "        x = batch[0]  # Get the EEG data\n",
        "        mask = generate_mask(x)  # Generate masks with the correct shape\n",
        "        print(f\"Shape of x: {x.shape}\")\n",
        "        print(f\"Shape of mask: {mask.shape}\")\n",
        "\n",
        "        # Forward pass\n",
        "        enc_output, pred_output, recon_output, momentum_output = model(x, mask)\n",
        "        print(f\"Shape of enc_output: {enc_output.shape}\")  # Doit être (batch_size, num_channels, embed_dim)\n",
        "        print(f\"Shape of pred_output: {pred_output.shape}\")  # Doit être (batch_size, num_channels, embed_dim)\n",
        "        print(f\"Shape of recon_output: {recon_output.shape}\")  # Doit être (batch_size, num_channels, num_timepoints)\n",
        "        print(f\"Shape of momentum_output: {momentum_output.shape}\")  # Doit être (batch_size, num_channels, embed_dim)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = dual_self_supervised_loss(enc_output, pred_output, recon_output, momentum_output, mask)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "id": "s4pl5OcBeeeK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "3ee8aa36-4167-4b1d-a6de-218e9fac99b1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x: torch.Size([32, 59, 1024])\n",
            "Shape of mask: torch.Size([32, 59, 1024])\n",
            "Shape of enc_output: torch.Size([32, 59, 512])\n",
            "Shape of pred_output: torch.Size([32, 59, 512])\n",
            "Shape of recon_output: torch.Size([32, 59, 1024])\n",
            "Shape of momentum_output: torch.Size([32, 59, 512])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (512) must match the size of tensor b (59) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-81bc7d4720ac>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdual_self_supervised_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Backward pass and optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-bb8bf4fb11df>\u001b[0m in \u001b[0;36mdual_self_supervised_loss\u001b[0;34m(enc_output, pred_output, recon_output, momentum_output, mask)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Reconstruction loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mreconstruction_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_output_resized\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Total loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (512) must match the size of tensor b (59) at non-singleton dimension 1"
          ]
        }
      ]
    }
  ]
}